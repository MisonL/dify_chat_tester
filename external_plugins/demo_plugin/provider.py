import threading
import time
from typing import Callable, List, Optional

from dify_chat_tester.providers.base import AIProvider


class DemoProvider(AIProvider):
    """ç¤ºä¾‹ä¾›åº”å•†å®ç°
    
    æ¨¡æ‹Ÿå„ç§å¤æ‚çš„ AI äº¤äº’åœºæ™¯ï¼Œç”¨äºæµ‹è¯•å’Œæ¼”ç¤ºã€‚
    """

    def get_models(self) -> List[str]:
        return ["demo-fast", "demo-slow", "demo-reasoning", "demo-tools"]

    def select_model(self, available_models: List[str]) -> str:
        """ã€å¯é€‰ã€‘ è‡ªåŠ¨é€‰æ‹©é»˜è®¤æ¨¡å‹ï¼Œè·³è¿‡ç”¨æˆ·äº¤äº’"""
        return "demo-reasoning"

    def select_role(self, available_roles: List[str]) -> str:
        """ã€å¯é€‰ã€‘ è‡ªåŠ¨é€‰æ‹©é»˜è®¤è§’è‰²ï¼Œè·³è¿‡ç”¨æˆ·äº¤äº’"""
        return "help-desk"

    def send_message(
        self,
        message: str,
        model: str,
        role: str = "å‘˜å·¥",
        history: Optional[List[dict]] = None,
        conversation_id: Optional[str] = None,
        stream: bool = True,
        show_indicator: bool = True,
        show_thinking: bool = True,
        stream_callback: Optional[Callable[[str, str], None]] = None,
    ) -> tuple:
        """å¤„ç†æ¶ˆæ¯å‘é€"""
        
        full_response = ""
        
        # æ¨¡æ‹Ÿä¸åŒæ¨¡å‹çš„è¡Œä¸º
        if model == "demo-reasoning":
            full_response = self._handle_reasoning_flow(message, stream, show_thinking, stream_callback)
        elif model == "demo-tools":
            full_response = self._handle_tool_flow(message, stream, stream_callback)
        else:
            full_response = f"æ”¶åˆ°æ¶ˆæ¯: {message}\nå½“å‰æ¨¡å‹: {model}\nå½“å‰è§’è‰²: {role}"
            if stream and stream_callback:
                for char in full_response:
                    time.sleep(0.02)
                    stream_callback("text", full_response[:full_response.index(char)+1])

        return full_response, True, None, "demo-session-id"

    def _handle_reasoning_flow(self, message, stream, show_thinking, callback):
        """æ¨¡æ‹Ÿå¸¦æ€è€ƒè¿‡ç¨‹çš„å“åº”"""
        response_text = "æ ¹æ®åˆšæ‰çš„åˆ†æï¼Œç­”æ¡ˆæ˜¯ 42ã€‚"
        
        if stream and callback:
            # 1. å‘é€æ€è€ƒè¿‡ç¨‹
            if show_thinking:
                thoughts = ["æ­£åœ¨åˆ†æç”¨æˆ·æ„å›¾...", "æ£€ç´¢çŸ¥è¯†åº“...", "éªŒè¯æ•°æ®å‡†ç¡®æ€§...", "ç”Ÿæˆæœ€ç»ˆå›å¤..."]
                for thought in thoughts:
                    time.sleep(0.5)
                    callback("thinking", f"ğŸ¤” {thought}\n")
            
            # 2. å‘é€æ­£æ–‡
            current_text = ""
            for char in response_text:
                time.sleep(0.05)
                current_text += char
                callback("text", current_text)
                
        return response_text

    def _handle_tool_flow(self, message, stream, callback):
        """æ¨¡æ‹Ÿå·¥å…·è°ƒç”¨çš„å“åº”"""
        response_text = "å·²ä¸ºæ‚¨æŸ¥è¯¢åˆ°ä»Šæ—¥å¤©æ°”ä¸ºæ™´æœ—ï¼Œæ°”æ¸© 25â„ƒã€‚"
        
        if stream and callback:
            # 1. æ¨¡æ‹Ÿå·¥å…·è°ƒç”¨å¼€å§‹
            time.sleep(0.5)
            callback("tool_call", "weather_api --city=Shenzhen")
            
            # 2. æ¨¡æ‹Ÿè¿è¡Œè€—æ—¶
            time.sleep(1.5)
            
            # 3. æ¨¡æ‹Ÿå·¥å…·è¿”å›ç»“æœ
            callback("tool_result", "Status: 200 OK, Data: {temp: 25, condition: sunny}")
            
            # 4. ç”Ÿæˆå›å¤
            current_text = ""
            for char in response_text:
                time.sleep(0.05)
                current_text += char
                callback("text", current_text)
                
        return response_text
